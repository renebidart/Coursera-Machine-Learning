Exercise Classification
========================================================



```{r}
library(doParallel)
cl<-makeCluster(detectCores())
registerDoParallel(cl)

library(caret)
setwd("/Users/rene_b23/desktop/coursera/machine learning")
training1<-as.data.frame(read.csv("./pml-training.csv"))
testing<-as.data.frame(read.csv("./pml-testing.csv"))
```

Create partitions for use with cross validation:
```{r}
inTrain = createDataPartition(training1$classe, p = 3/4)[[1]]
training = training1[ inTrain,]
testing2 = training1[-inTrain,]
```


```{r}
##Get info

str(training)

apply(training, 2, function(x) length(which(is.na(x))))

```

This shows that there are a large number of variables mostly composed of NA's. These columns clearly do not anything to the data so should be removed before any analysis.

The best way to remove these is to remove all columns with near zero variance, as this incluses the NA  columns as well as other unnecessary columns.
Cutoffs were changed to include more data.


```{r}

x<-nearZeroVar(testing, freqCut = 95/20, uniqueCut = 10, saveMetrics = FALSE)

testSub<-testing[,-x]
trainSub<-training[,-x]

##x<-nearZeroVar(training, freqCut = 95/15, uniqueCut = 10, saveMetrics = FALSE)
```



Create the random forest model and make the prediction on the test set.

```{r}

model <- train(classe~.,method = "rf", data = trainSub)


prediction <- predict(model, newdata = testSub)

```



Use cross validation to see how effective the prediction was:
```{r}
confusionMatrix(testing2$classe,predict(model,testing2)) 

```